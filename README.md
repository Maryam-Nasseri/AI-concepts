# AI-concepts
This repository is a mini-course for beginners on AI concepts and terms with their video links in the second section:

## Basic AI Terms and Concepts Used in the Following Tutorial Videos:

**Neural Network** is a network of neurons forming two or more layers. Think of the neurons as receiving points of values, with two specific values called "weight" and "bias". Input values are passed to the first layer where the output of each neuron is a weighted sum of its inputs, plus the bias. The output is passed on to the neurons in the next layer and so on, towards the final layer of the network, where the final output or the decision is received. 

**Optimizer** is an algorithm that adjusts the neurons' weights and biases as the parameters of a neural network. The optimisation of parameters is meant to minimise the loss function during the training stage.

**Fine-tuning** is the process of making new information accessible to a generative model by updating its weights via training the layers closer to the output.

**In Context Learning or ICL** is an alternative to fine-tuning whereby the user provides the generative model with additional examples of the desired response at the prompt. ICL does not require any model training or parameter tuning as done with fine-tuning.

**RAG or the retrieval augmented generation** method is another alternative to fine-tuning whereby the user provides the pre-trained model with additional information from external sources of data, e.g., a PDF file, spreadsheet data, a web link, or even a code repository.

**Large Language Models** are predictive models generated by various neural network methods to predict the next word (or token) in a text sequence (e.g., a sentence).

## Table of Content: Videos about AI Concepts and Terms:

[Transformer Language Models Simplified in JUST 3 MINUTES!](#transformer-language-models-simplified-in-just-3-minutes!)

[Beginner's guide to how language models work: full history of language models](#beginner's-guide-to-how-language-models-work-full-history-of-language-models)

[Best LLM? How to Evaluate Language Models In Hugging Face](#best-lLM?-how-to-evaluate-language-models-in-hugging-face)

[The Concept of Backpropagation Simplified in JUST 2 MINUTES! --Neural Networks](#the-concept-of-backpropagation-simplified-in-jUST-2-mINUTES!-neural-networks)

[Mamba Language Model Simplified In JUST 5 MINUTES!](#mamba-language-model-simplified-in-jUST-5-mINUTES!)

[Is Mamba LLM Destroying Transformers? Language Model Comparison in AI](#is-mamba-lLM-destroying-transformers?-language-model-comparison-in-aI)

[What Is An Agentic Workflow? Six Main Systems For AI Agents](#what-is-an-agentic-workflow?-six-main-systems-for-aI-agents)

## Transformer Language Models Simplified in JUST 3 MINUTES!

This is Transformers simplified for beginners, based on the journal article ‘Attention Is All You Need’ 2017 by Google researchers. 

Main terms and concepts: Attention mechanism, contextual understanding, encoder and decoder, multi-head, positional encoding, self-attention.

[![Watch the video Transformer Language Model from Analytics Camp](https://img.youtube.com/vi/6n-mOFlhbGI/maxresdefault.jpg)](https://youtu.be/6n-mOFlhbGI) 



## Beginner's guide to how language models work full history of language models

This is LLM simplified for beginners: the fascinating journey of the evolution of language models, from rule-based models to statistical models, neural networks and transformers. 

Main terms and concepts: probability of the next word, word sequences, rule-based algorithms, deterministic algorithms, contextual understanding, probabilistic algorithm, chain rule, natural language processing.

[![Watch the video on how language models work LLM understanding Analytics Camp](https://img.youtube.com/vi/n_5spvz-2KI/maxresdefault.jpg)](https://youtu.be/n_5spvz-2KI) 


## Best LLM? How to Evaluate Language Models In Hugging Face

A full explanation of the Hugging Face LLM evaluation Scheme and tests: Measuring Massive Multitask Language Understanding (MMLU), AI2 Reasoning Challenge (ARC), the TruthfulQA which measures whether a language model is truthful in generating answers to questions, HellaSwag which challenges LLMs with a new task of commonsense natural language inference, Winogrande as a test of pronoun resolution problems, and the GSM8k multi-step test of mathematical reasoning. 

[![Watch the video how to choose the best language model](https://img.youtube.com/vi/PXX2OO7s8wY/maxresdefault.jpg)](https://youtu.be/PXX2OO7s8wY) 



## The Concept of Backpropagation Simplified in JUST 2 MINUTES! --Neural Networks

A beginner and easy-to-follow explanation of Backpropagation in Neural Networks, and how it helps to reduce the error in predicting the next word in a sequence in a text. 

[![Watch the video on the concept of backpropagation simplified](https://img.youtube.com/vi/gyW5gQnsm3w/maxresdefault.jpg)](https://youtu.be/gyW5gQnsm3w) 


## Mamba Language Model Simplified In JUST 5 MINUTES!

A super simplified explanation of the Mamba language model with the Selective State Space Model (Selective SSM architecture). It shows how Mamba’s AI architecture uses the Selective State Space Model to figure out which parts of the data. e.g., which words in a word sequence, are connected and how they might affect what happens next, e.g., to predict which word comes next.

[![Watch the video on Mamba Language Model with Selective State Space](https://img.youtube.com/vi/e7TFEgq5xiY/maxresdefault.jpg)](https://youtu.be/e7TFEgq5xiY) 


## Is Mamba LLM Destroying Transformers? Language Model Comparison in AI

The model architectures and performance differences of the Transformer and Mamba language models. I will compare the functionalities of the main AI and machine learning models, and show the necessary improvements in the Mamba AI model compared to its Recurrent Neural Networks predecessor such as Long Short Term Memory or LSTM, and Gated networks. 

[![Watch the video on Mamba Language Model with Selective State Space](https://img.youtube.com/vi/pfqNXaAOh1U/maxresdefault.jpg)](https://youtu.be/pfqNXaAOh1U)


## What Is An Agentic Workflow? Six Main Systems For AI Agents 

Researchers in artificial intelligence believe that the path to AGI or Artificial General Intelligence is by leveraging the Agentic AI workflow. But what exactly is an agentic AI workflow and how can we use it in our daily tasks and business decision-making?

Key terms and concepts: multi-agent, self-refine, refinement method, Reflexion method, verbal reinforcement learning, HuggingGPT, chain of thought prompting, AutoGen, retrieval-augmented chat, Multi-agent coding

[![Watch the video on Mamba Language Model with Selective State Space](https://img.youtube.com/vi/lA3Tju4VUho/maxresdefault.jpg)](https://youtu.be/lA3Tju4VUho)


## AI Terms and Concepts Explained!

Retrieval Augmented Generation (RAG) vs In-Context-Learning (ICL) vs Fine-Tuning LLMs: 
[![Watch the video explaining main terms and concepts in AI aRTIFICIAL iNTELLIGENCE](https://img.youtube.com/vi/bl9jw2BZCxc/maxresdefault.jpg)](https://youtu.be/bl9jw2BZCxc)
