# AI-concepts
This repository is a collection of AI concepts and terms with their video links:

[Transformer Language Models Simplified in JUST 3 MINUTES!](#transformer-language-models-simplified-in-just-3-minutes!)

[Beginner's guide to how language models work: full history of language models](#beginner's-guide-to-how-language-models-work-full-history-of-language-models)

[Best LLM? How to Evaluate Language Models In Hugging Face](#best-lLM?-how-to-evaluate-language-models-in-hugging-face)

[The Concept of Backpropagation Simplified in JUST 2 MINUTES! --Neural Networks](#the-concept-of-backpropagation-simplified-in-jUST-2-mINUTES!-neural-networks)

## Transformer Language Models Simplified in JUST 3 MINUTES!

This is Transformers simplified for beginners, based on the journal article ‘Attention Is All You Need’ 2017 by Google researchers. 

[![Watch the video Transformer Language Model from Analytics Camp](https://img.youtube.com/vi/6n-mOFlhbGI/maxresdefault.jpg)](https://youtu.be/6n-mOFlhbGI) 


## Beginner's guide to how language models work full history of language models

This is LLM simplified for beginners: the fascinating journey of the evolution of language models, from rule-based models to statistical models, neural networks and transformers. 

[![Watch the video on how language models work LLM understanding Analytics Camp](https://img.youtube.com/vi/n_5spvz-2KI/maxresdefault.jpg)](https://youtu.be/n_5spvz-2KI) 


## Best LLM? How to Evaluate Language Models In Hugging Face

A full explanation of the Hugging Face LLM evaluation Scheme and tests: Measuring Massive Multitask Language Understanding (MMLU), AI2 Reasoning Challenge (ARC), the TruthfulQA which measures whether a language model is truthful in generating answers to questions, HellaSwag which challenges LLMs with a new task of commonsense natural language inference, Winogrande as a test of pronoun resolution problems, and the GSM8k multi-step test of mathematical reasoning. 

[![Watch the video how to choose the best language model](https://img.youtube.com/vi/PXX2OO7s8wY/maxresdefault.jpg)](https://youtu.be/PXX2OO7s8wY) 



## The Concept of Backpropagation Simplified in JUST 2 MINUTES! --Neural Networks

A beginner and easy-to-follow explanation of Backpropagation in Neural Networks, and how it helps to reduce the error in predicting the next word in a sequence in a text. 

[![Watch the video on the concept of backpropagation simplified](https://img.youtube.com/vi/gyW5gQnsm3w/maxresdefault.jpg)](https://youtu.be/gyW5gQnsm3w) 


## Mamba Language Model Simplified In JUST 5 MINUTES!

A super simplified explanation of the Mamba language model with the Selective State Space Model (Selective SSM architecture). It shows how Mamba’s AI architecture uses the Selective State Space Model to figure out which parts of the data. e.g., which words in a word sequence, are connected and how they might affect what happens next, e.g., to predict which word comes next.

[![Watch the video on Mamba Language Model with Selective State Space](https://img.youtube.com/vi/e7TFEgq5xiY/maxresdefault.jpg)](https://youtu.be/e7TFEgq5xiY) 
